{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laborator_6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-pub-ro/ML/blob/master/lab/lab6/Laborator_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3a1x3D2pJlE"
      },
      "source": [
        "# Învățare Automată\n",
        "# Învățare prin Recompensă - rezolvarea proceselor de decizie Markov prin tehnici de programare dinamică (Value Iteration, Policy Iteration)\n",
        "### Autori:\n",
        "* Tudor Berariu - 2018\n",
        "* Alexandru Sorici - 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6-C84FKpUfB"
      },
      "source": [
        "## 1. Scopul laboratorului"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTKbkxAwpYhl"
      },
      "source": [
        "Scopul laboratorului îl reprezintă înțelegerea conceptelor de proces markov de decizie (MDP), politică, valoare de stare, precum și implementarea unor metode de programare dinamică pentru rezolvarea problemei de control a unui MDP.\n",
        "\n",
        "În cadrul laboratorului veți:\n",
        "- implementa algoritmul de iterare a politicilor\n",
        "- implementa algoritmul de iterare a valorilor de stare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i_6oVDI-zp5"
      },
      "source": [
        "## 2. Workspace setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTs6cwy5_Na7"
      },
      "source": [
        "### Câteva bibioteci de care vom avea nevoie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Y6WMfQ_R5L"
      },
      "source": [
        "import sys\n",
        "import os.path\n",
        "from argparse import ArgumentParser\n",
        "from copy import copy\n",
        "from random import choice\n",
        "import numpy as np\n",
        "\n",
        "from typing import Dict, List, Tuple"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhMSc8oHEdLK"
      },
      "source": [
        "### Definirea unui labirint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09ToJHh-Ef2S"
      },
      "source": [
        "class Maze:\n",
        "\n",
        "    NORTH, EAST, SOUTH, WEST = 0, 1, 2, 3  # actions\n",
        "\n",
        "    DYNAMICS = {  # the stochastic effects of actions\n",
        "        NORTH: {(0, -1): 0.1, (-1, 0): .8, (0, 1): .1},\n",
        "        EAST: {(-1, 0): 0.1, (0, 1): .8, (1, 0): .1},\n",
        "        SOUTH: {(0, 1): 0.1, (1, 0): .8, (0, -1): .1},\n",
        "        WEST: {(1, 0): 0.1, (0, -1): .8, (-1, 0): .1},\n",
        "    }\n",
        "\n",
        "    WALL, EMPTY = \"x\", \" \"\n",
        "\n",
        "    VISUALS = {\n",
        "        (0, 0, 1, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND RIGHT}\",\n",
        "        (1, 0, 0, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND LEFT}\",\n",
        "        (1, 0, 1, 0): \"\\N{BOX DRAWINGS HEAVY HORIZONTAL}\",\n",
        "        (0, 1, 1, 0): \"\\N{BOX DRAWINGS HEAVY UP AND RIGHT}\",\n",
        "        (1, 1, 0, 0): \"\\N{BOX DRAWINGS HEAVY UP AND LEFT}\",\n",
        "        (0, 1, 0, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL}\",\n",
        "        (1, 1, 1, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND HORIZONTAL}\",\n",
        "        (1, 1, 1, 0): \"\\N{BOX DRAWINGS HEAVY UP AND HORIZONTAL}\",\n",
        "        (1, 1, 0, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND LEFT}\",\n",
        "        (1, 0, 1, 1): \"\\N{BOX DRAWINGS HEAVY DOWN AND HORIZONTAL}\",\n",
        "        (0, 1, 1, 1): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND RIGHT}\",\n",
        "        (1, 0, 0, 0): \"\\N{BOX DRAWINGS HEAVY LEFT}\",\n",
        "        (0, 1, 0, 0): \"\\N{BOX DRAWINGS HEAVY UP}\",\n",
        "        (0, 0, 1, 0): \"\\N{BOX DRAWINGS HEAVY RIGHT}\",\n",
        "        (0, 0, 0, 1): \"\\N{BOX DRAWINGS HEAVY DOWN}\",\n",
        "        (0, 0, 0, 0): \"\\N{BOX DRAWINGS HEAVY VERTICAL AND HORIZONTAL}\",\n",
        "        WEST: \"\\N{LEFTWARDS ARROW}\",\n",
        "        NORTH: \"\\N{UPWARDS ARROW}\",\n",
        "        EAST: \"\\N{RIGHTWARDS ARROW}\",\n",
        "        SOUTH: \"\\N{DOWNWARDS ARROW}\",\n",
        "    }\n",
        "\n",
        "    def __init__(self, map_name):\n",
        "        self._rewards, self._cells = {}, []\n",
        "        with open(os.path.join(\"maps\", map_name), \"r\") as map_file:\n",
        "            for line in map_file.readlines():\n",
        "                if \":\" in line:\n",
        "                    name, value = line.strip().split(\":\")\n",
        "                    self._rewards[name] = float(value)\n",
        "                else:\n",
        "                    self._cells.append(list(line.strip()))\n",
        "        self._states = [(i, j) for i, row in enumerate(self._cells)\n",
        "                        for j, cell in enumerate(row) if cell != Maze.WALL]\n",
        "\n",
        "    @property\n",
        "    def actions(self):\n",
        "        return [Maze.NORTH, Maze.EAST, Maze.SOUTH, Maze.WEST]\n",
        "\n",
        "    @property\n",
        "    def states(self):\n",
        "        return copy(self._states)\n",
        "\n",
        "    def is_final(self, state):\n",
        "        row, col = state\n",
        "        return self._cells[row][col] != Maze.EMPTY\n",
        "\n",
        "    def effects(self, state, action):\n",
        "        if self.is_final(state):\n",
        "            return []\n",
        "        row, col = state\n",
        "        next_states = {}\n",
        "        for (d_row, d_col), prob in Maze.DYNAMICS[action].items():\n",
        "            next_row, next_col = row + d_row, col + d_col\n",
        "            if self._cells[next_row][next_col] == Maze.WALL:\n",
        "                next_row, next_col = row, col\n",
        "            if (next_row, next_col) in next_states:\n",
        "                prev_prob, _ = next_states[(next_row, next_col)]\n",
        "                prob += prev_prob\n",
        "            cell = self._cells[next_row][next_col]\n",
        "            reward = self._rewards[\"default\" if cell == Maze.EMPTY else cell]\n",
        "            next_states[(next_row, next_col)] = (prob, reward)\n",
        "        return [(s, p, r) for s, (p, r) in next_states.items()]\n",
        "\n",
        "    def print_policy(self, policy):\n",
        "        last_row = []\n",
        "        height = len(self._cells)\n",
        "\n",
        "        for row, row_cells in enumerate(self._cells):\n",
        "            width = len(row_cells)\n",
        "            for col, cell in enumerate(row_cells):\n",
        "                if cell == Maze.WALL:\n",
        "                    north, south, west, east = 0, 0, 0, 0\n",
        "                    if last_row and len(last_row) > col:\n",
        "                        north = last_row[col] == Maze.WALL\n",
        "                    if row + 1 < height:\n",
        "                        south = self._cells[row + 1][col] == Maze.WALL\n",
        "                    if col > 0:\n",
        "                        west = row_cells[col - 1] == Maze.WALL\n",
        "                    if col + 1 < width:\n",
        "                        east = row_cells[col + 1] == Maze.WALL\n",
        "                    sys.stdout.write(Maze.VISUALS[(west, north, east, south)])\n",
        "                elif self.is_final((row, col)):\n",
        "                    sys.stdout.write(cell)\n",
        "                else:\n",
        "                    action = policy[(row, col)]\n",
        "                    sys.stdout.write(Maze.VISUALS[action])\n",
        "            sys.stdout.write(\"\\n\")\n",
        "            last_row = row_cells\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    def print_values(self, v):\n",
        "        for r, row_cells in enumerate(self._cells):\n",
        "            print(\" | \".join([\"%5.2f\" % v[(r, c)] if cell == Maze.EMPTY else \"     \"\n",
        "                              for c, cell in enumerate(row_cells)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-G9p2SH-r0V"
      },
      "source": [
        "## Cerințe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWDvai4ooN43"
      },
      "source": [
        "MAP_NAME = 'complex'  #@param ['simple', 'complex', 'be_careful', 'suffer']\n",
        "gamma = 0.8 #@param {type: \"slider\", min: 0.0, max: 1.0, step: 0.1}\n",
        "max_delta = 1e-8 #@param {type:\"float\"}."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8xeC9hAoN44"
      },
      "source": [
        "### Cerința 1\n",
        "Implementați funcția **policy_iteration** pentru calculul politicii optime și a tabelului de utilitate așteptată pentru fiecare stare (celulă din grid) a labirintului. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MVchj3tg8hY"
      },
      "source": [
        "def sum_formula(game, state, action):\n",
        "  sum = 0\n",
        "  eff = game.effects(state, action)\n",
        "  for elem in eff:\n",
        "    sum += elem[1] * ( elem[2] + gamma * v[elem[0]])\n",
        "  return sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKiDJc2uqIcn"
      },
      "source": [
        "def policy_iteration(game: Maze) -> Tuple[Dict[Tuple[int, int], int], Dict[Tuple[int, int], float]]:\n",
        "    policy = {s: choice(game.actions)\n",
        "              for s in game.states if not game.is_final(s)}\n",
        "    v = {s: 0 for s in game.states}\n",
        "\n",
        "    ro = 1\n",
        "    eps = max_delta\n",
        "    \n",
        "    done = False\n",
        "    while done == False:\n",
        "      ro = 1\n",
        "      while ro > eps:\n",
        "        ro = 0\n",
        "        for s in game.states:\n",
        "          if not game.is_final(s):\n",
        "            v_old = v[s]\n",
        "            v[s] = sum_formula(game, s, policy[s])\n",
        "            ro = max(ro, abs(v[s] - v_old))\n",
        "\n",
        "        done = True\n",
        "        for s in game.states:\n",
        "          if not game.is_final(s):\n",
        "            a_old = policy[s]\n",
        "            argmax = sum_formula(game, s, game.actions[0])\n",
        "            for a in game.actions:\n",
        "              res = sum_formula(game, s, a)\n",
        "              if argmax <= res:\n",
        "                argmax = res\n",
        "                policy[s] = a\n",
        "            if a_old != policy[s]:\n",
        "              done = False\n",
        "\n",
        "    return policy, v\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buIrg3R6oN45"
      },
      "source": [
        "### Cerința 2\n",
        "Implementați funcția **value_iteration** pentru calculul politicii optime și a tabelului de utilitate așteptată pentru fiecare stare (celulă din grid) a labirintului. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5BJySTXDfh3"
      },
      "source": [
        "def value_iteration(game: Maze) -> Tuple[Dict[Tuple[int, int], int], Dict[Tuple[int, int], float]]:\n",
        "    v = {s: 0 for s in game.states}\n",
        "    ro = 1\n",
        "    eps = max_delta\n",
        "    \n",
        "    while ro > eps:\n",
        "      ro = 0\n",
        "      for s in game.states:\n",
        "        if not game.is_final(s):\n",
        "          v_old = v[s]\n",
        "          argmax = sum_formula(game, s, game.actions[0])\n",
        "          for a in game.actions:\n",
        "            v_aux = sum_formula(game, s, a)\n",
        "            if argmax <= v_aux:\n",
        "              argmax = v_aux\n",
        "          v[s] = argmax\n",
        "          ro = max(ro, abs(v[s] - v_old))\n",
        "\n",
        "    for s in game.states:\n",
        "      if not game.is_final(s):\n",
        "        argmax = sum_formula(game, s, game.actions[0])\n",
        "        for a in game.actions:\n",
        "          res = sum_formula(game, s, a)\n",
        "          if argmax <= res:\n",
        "            argmax = res\n",
        "            policy[s] = a\n",
        "\n",
        "    return policy, v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6CoJAktMV_I"
      },
      "source": [
        "## Evaluare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "lDueFUXSMUwL",
        "outputId": "1bbe3240-a686-44c8-e557-1301b24b705d"
      },
      "source": [
        "#@title\n",
        "    \n",
        "game = Maze(MAP_NAME)\n",
        "\n",
        "print(\"Policy iteration:\")\n",
        "policy, v = policy_iteration(game)\n",
        "game.print_values(v)\n",
        "game.print_policy(policy)\n",
        "\n",
        "print(\"Value iteration:\")\n",
        "policy, v = value_iteration(game)\n",
        "game.print_values(v)\n",
        "game.print_policy(policy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-69173a43d219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAP_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Policy iteration:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-db462448d864>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, map_name)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"maps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmap_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\":\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'maps/suffer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itw8fFn1oN47"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}