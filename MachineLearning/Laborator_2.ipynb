{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laborator_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CLd24Gc0Qoz"
      },
      "source": [
        "# Învățare Automată\n",
        "# Arbori de decizie. Păduri aleatoare\n",
        "### Autori:\n",
        "* Tudor Berariu - 2016\n",
        "* George Muraru - 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxigVMh10QsL"
      },
      "source": [
        "## 1. Scopul laboratorului"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CycSr6E4ltrs"
      },
      "source": [
        "Scopul laboratorului îl reprezintă întelegerea conceptului de arbore de decizie și implementarea unor clasificatori bazați pe acest model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YWxF81W1jlU"
      },
      "source": [
        "## 2. Problema de rezolvat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3RQxoc61nrD"
      },
      "source": [
        "Problema de rezolvat ı̂n acest laborator este una de ı̂nvățare supervizată: fiind dat un **set de date X** ce conține exemple descrise printr-un set de **atribute discrete A** și etichetate cu **câte o clasă dintr-o mulțime cunoscută C**, să se construiască un model pentru clasificarea exemplelor noi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxWxuiO_16tZ"
      },
      "source": [
        "## 3. Arbore de decizie\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBXFgoNYlxdp"
      },
      "source": [
        "Un arbore de decizie este un clasificator ce aproximează funcții discrete.\n",
        "\n",
        "Într-un arbore de decizie există 2 tipuri de noduri:\n",
        "* *noduri intermediare* - conține un test pentru un atribut și are câte un arc (și implicit un subarbore) pentru fiecare valoare posibiliă a atributului\n",
        "* *noduri frunză* - este etichetat cu o clasă\n",
        "\n",
        "Pentru **a clasifica un obiect nou** se pornește din rădăcina arborelui și din fiecare nod se coboară pe arcul corespunzător valorii atributului pe care o are obiectul dat. Atunci când se ajunge ı̂ntr-un nod frunză, clasa acestuia va reprezenta predicția arborelui."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQvktw_WbZpk"
      },
      "source": [
        "## 4. Păduri de arbori aleatori"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imU3HcNzl13s"
      },
      "source": [
        "*Pădurile de arbori aleatori* (eng. Random Forest) este un model format din mai mulți arbori de decizie.\n",
        "\n",
        "Se bazează pe 2 hiperparametrii:\n",
        "* Eșantionare aleatoare din setul de date de antrenament\n",
        "* Subseturi aleatoare de atribute considerate la împărțirea pe mai multi subarbori\n",
        "\n",
        "Predicția, utilizând un astfel de model, se bazează pe clasa majoritară oferită de predicțiile indepente ale tuturor arborilor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XnuEfno1n4D"
      },
      "source": [
        "## 5. Workspace Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQvzJhiWfzm9"
      },
      "source": [
        "### Câteva biblioteci de care vom avea nevoie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2lKg7o7nZxo"
      },
      "source": [
        "from math import log2\n",
        "import csv\n",
        "import os\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVVLxc0geBix"
      },
      "source": [
        "### Hiperparametrii necesari rulării"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTGgZTdXeHaS"
      },
      "source": [
        "DATASET_NAME = 'Tennis'  #@param ['Chess', 'Car', 'Tennis']\n",
        "\n",
        "# Adâncimea arborilor\n",
        "D = 7 #@param {type: \"slider\", min: 2, max: 10}\n",
        "\n",
        "# Procentul de exemple din setul de date utilizat la construcția arborilor\n",
        "P = 50 #@param {type: \"slider\", min: 1, max: 100}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyJFPSkseHlf"
      },
      "source": [
        "### Funcții ajutătoare pentru descărcarea și lucrul cu setul de date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZtaRrKceKKg"
      },
      "source": [
        "class Node:\n",
        "    \"\"\" Representation for a node from the decision tree \"\"\"\n",
        "    def __init__(self, label):\n",
        "        \"\"\"\n",
        "            for non-leafs it is the name of the attribute\n",
        "            for leafs it is the class\n",
        "        \"\"\"\n",
        "        self.label = label\n",
        "        \n",
        "        # Dictionary of (attribute value, nodes)\n",
        "        self.children = {}\n",
        "    \n",
        "    def display(self, string):\n",
        "        print(string + self.label)\n",
        "        string += \"\\t\"\n",
        "        if self.children:\n",
        "            for key, value in self.children.items():\n",
        "                print(string + key)\n",
        "                value.display(string + \"\\t\")\n",
        "\n",
        "\n",
        "def getArchive(dataSetName):\n",
        "    \"\"\" Checks if a specific dataset is present in the local directory, if not,\n",
        "    downloads it.\n",
        "\n",
        "    Args:\n",
        "        dataSetName (str): the dataset name\n",
        "    \"\"\"\n",
        "    dataset_file = \"datasets\" + os.sep + dataSetName.lower()\n",
        "    print(dataset_file)\n",
        "    \n",
        "    from os import path\n",
        "    if not path.isfile(dataset_file):\n",
        "        import urllib\n",
        "        print(\"Downloading...\")\n",
        "        urllib.request.urlretrieve(dataset_url, filename=dataset_file)\n",
        "        assert(path.isfile(dataset_file))\n",
        "        print(\"Got the archive\")\n",
        "    else:\n",
        "        print(f\"{dataset_file} already in the local directory\")\n",
        "\n",
        "\n",
        "def getDataSet(dataSetName):\n",
        "    \"\"\" Reads a dataset\n",
        "\n",
        "    Args:\n",
        "        dataSetName (str): Name for the dataset\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing (classes, attributes, examples):\n",
        "        classes (set): the classes that are found in the dataset\n",
        "        attributes (list of strings): the attributes for the dataset\n",
        "        examples (list of dictionaries): one example contains an entry as\n",
        "            (attribute name, attribute value)\n",
        "    \"\"\"\n",
        "\n",
        "    dataset_file = \"datasets\" + os.sep + dataSetName.lower()\n",
        "\n",
        "    f_in = open(dataset_file, 'r')\n",
        "    csv_reader = csv.reader(f_in, delimiter=\",\")\n",
        "\n",
        "    # Read the header row\n",
        "    row = next(csv_reader)\n",
        "\n",
        "    # The last element represents the class\n",
        "    attributeNames = row[:-1]\n",
        "    \n",
        "    examples = []\n",
        "    classes = set()\n",
        "\n",
        "    for row in csv_reader:\n",
        "        *attributes, label = row\n",
        "        classes.add(label)\n",
        "        example = dict(zip(attributeNames, attributes))\n",
        "        example[\"CLASS\"] = label\n",
        "        examples.append(example)\n",
        "    \n",
        "    f_in.close()\n",
        "    return classes, attributeNames, examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVpmhw63j89K"
      },
      "source": [
        "### Descărcare și încarcare set de date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8fxQ-xekLty",
        "outputId": "7bbf4453-ef49-45bb-eb9c-acaca5acd02a"
      },
      "source": [
        "getArchive(DATASET_NAME)\n",
        "classes, attributes, examples = getDataSet(DATASET_NAME)\n",
        "examples\n",
        "attributes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datasets/tennis\n",
            "datasets/tennis already in the local directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Outlook', 'Temperature', 'Humidity', 'Windy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgYby0WVetLL"
      },
      "source": [
        "## 6. Cerințe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU0xmCIFr-fi"
      },
      "source": [
        "1. [3 pct] Implementați o funcție recursivă *randomTree* care construiește arbori de decizie de adâncime **d** pe baza unui **set de date X** și a unei **mulțimi de atribute A** astfel:\n",
        " * Dac̆a *d = 0*, atunci se construiește un nod frunză cu clasa majoritară din X.\n",
        " * Dacă *d > 0*, atunci se alege aleator un atribut $a_i$ din A și se construiește câte un subarbore pentru fiecare valoare $v_j$ a atributului $a_i$ apelând *randomTree* pentru *d − 1*:\n",
        "$$\n",
        "X_{i/j} = \\{x \\in X|a_{i}(x) = v_k\\}\\\\\n",
        "A_{new} = A \\setminus \\{a_i\\}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOJjGaBUth4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5495e4-3e63-48d4-f1c8-a27f25f82a62"
      },
      "source": [
        "def randomTree(d, X, A):\n",
        "   # Cerință 1\n",
        "   if d == 0:\n",
        "     return Node(majClass(X))\n",
        "   randomA = random.choice(A)\n",
        "   auxA = A[:]\n",
        "   auxA.remove(randomA)\n",
        "   uniqueVals = []\n",
        "   auxX = X\n",
        "   nod = Node(randomA)\n",
        "   for elem in X:\n",
        "     if not elem[randomA] in uniqueVals:\n",
        "      nod.children[elem[randomA]] = randomTree(d-1, filterX(X, randomA, elem[randomA]), auxA)\n",
        "      uniqueVals.append(elem[randomA])\n",
        "   return nod\n",
        "\n",
        "def filterX(X, key, val):\n",
        "  result = []\n",
        "  for elem in X:\n",
        "    if elem[key] == val:\n",
        "      result.append(elem)\n",
        "  return result\n",
        "\n",
        "def majClass(X):\n",
        "  classCount = {}\n",
        "  for elem in classes:\n",
        "    classCount[elem] = 0\n",
        "  for elem in X:\n",
        "    clasa = elem[\"CLASS\"]\n",
        "    classCount[clasa] = classCount[clasa] + 1\n",
        "  maxCount = -1\n",
        "  maxClass = \"\"\n",
        "  for elem in classCount:\n",
        "    if maxCount < classCount[elem]:\n",
        "       maxCount = classCount[elem]\n",
        "       maxClass = elem\n",
        "  return maxClass\n",
        "\n",
        "#testare\n",
        "auxAtt = attributes[:]\n",
        "auxEx = examples[:]\n",
        "root = randomTree(3, auxEx, auxAtt)\n",
        "root.display(\"- \")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- Windy\n",
            "- \tfalse\n",
            "- \t\tTemperature\n",
            "- \t\t\thot\n",
            "- \t\t\t\tOutlook\n",
            "- \t\t\t\t\tsunny\n",
            "- \t\t\t\t\t\tno\n",
            "- \t\t\t\t\tovercast\n",
            "- \t\t\t\t\t\tyes\n",
            "- \t\t\tmild\n",
            "- \t\t\t\tHumidity\n",
            "- \t\t\t\t\thigh\n",
            "- \t\t\t\t\t\tno\n",
            "- \t\t\t\t\tnormal\n",
            "- \t\t\t\t\t\tyes\n",
            "- \t\t\tcool\n",
            "- \t\t\t\tHumidity\n",
            "- \t\t\t\t\tnormal\n",
            "- \t\t\t\t\t\tyes\n",
            "- \ttrue\n",
            "- \t\tHumidity\n",
            "- \t\t\thigh\n",
            "- \t\t\t\tTemperature\n",
            "- \t\t\t\t\thot\n",
            "- \t\t\t\t\t\tno\n",
            "- \t\t\t\t\tmild\n",
            "- \t\t\t\t\t\tno\n",
            "- \t\t\tnormal\n",
            "- \t\t\t\tTemperature\n",
            "- \t\t\t\t\tcool\n",
            "- \t\t\t\t\t\tno\n",
            "- \t\t\t\t\tmild\n",
            "- \t\t\t\t\t\tyes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjYqUPSbe1gG"
      },
      "source": [
        "2. [3 pct] Implementați o funcție recursivă *id3* care construiește arbori de decizie pe baza unui **set de date X** și a unei **mulțimi de atribute A**.\n",
        "    \n",
        "  Trebuie avute în vedere următoarele aspecte:\n",
        "  * dacă toate exemplele din X aparțin unei singure clase C, atunci se construiește un nod frunză etichetat cu acea clasă C\n",
        "  * dacă nu mai exista atribute, atunci construiește nodul frunză etichetat cu cea mai frecventă clasă din X\n",
        "    \n",
        "  În caz contrar:\n",
        "  * se alege atributul $a^*$ care aduce cel mai mai mare câștig informațional și se construiește un *nod intermediar* corespunzător acestuia.\n",
        "\n",
        "  $$\n",
        "    entropy(X) = -\\sum_{c \\in C}\\frac{|X_c|}{|X|}log_2\\frac{|X_c|}{|X|}\n",
        "  $$\n",
        "  $$\n",
        "    gain(X, a) = entropy(X) - \\sum_{v_{j} \\in vals(a)} \\frac{|X_{i/j}|}{|X|}entropy(X_{i/j})\n",
        "  $$\n",
        "  $$\n",
        "    a^* = \\underset{a \\in A}{\\operatorname{arg max}}\\ gain(X, a)\n",
        "  $$\n",
        "\n",
        "  * pentru fiecare valoare posibilă $v_j$ a lui $a^*$ se construiește un subarbore apelând recursiv funcția *id3* pentru:\n",
        "\n",
        "$$\n",
        "  X_j = \\{x \\in X|a^*(x) = v_j\\}\\\\\n",
        "  A_{new} = A\\setminus\\{a^*\\}\n",
        "$$\n",
        "\n",
        "În cazul prezentat mai sus, entropia este utilizată pentru a măsura randomness-ul din date. Intuitiv, cu cât un eveniment are probabilitate mai mare să se întâmple atunci acesta va avea o entropia din ce în ce mai mică. Prin modul în care se construiește arborele *ID3* se încearcă reducerea entropiei alegând la fiecare pas atributele care ne ofera cea mai multă informație. Cât considerați că este entropia într-un *nod frunză*?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_vvpBBve0-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996d0d0a-c631-47ca-ba74-4008f0404036"
      },
      "source": [
        "def mostFrequentClass(X):\n",
        "    # TODO Cerință 2\n",
        "    return majClass(X)\n",
        "\n",
        "\n",
        "def entropy(X):\n",
        "    # TODO Cerință 2\n",
        "    entropy = 0\n",
        "    totalClasses = len(X)\n",
        "    classCount = {}\n",
        "    for elem in classes:\n",
        "      classCount[elem] = 0\n",
        "    for elem in X:\n",
        "      clasa = elem[\"CLASS\"]\n",
        "      classCount[clasa] = classCount[clasa] + 1\n",
        "    \n",
        "    for elem in classes:\n",
        "      if classCount[elem] != 0:\n",
        "        entropy = entropy - ((classCount[elem]/totalClasses) * log2(classCount[elem]/totalClasses))\n",
        "    return entropy\n",
        "\n",
        "def gain(X, A):\n",
        "    # TODO Cerință 2\n",
        "    gain = entropy(X)\n",
        "    uniqueSplits = []\n",
        "    for elem in X:\n",
        "      if not elem[A] in uniqueSplits:\n",
        "        uniqueSplits.append(elem[A])\n",
        "    for elem in uniqueSplits:\n",
        "      Xij = filterX(X, A, elem)\n",
        "      gain = gain - (len(Xij) / len(X)) * entropy(Xij)\n",
        "    return gain\n",
        "\n",
        "def isLeaf(X, A):\n",
        "  if len(A) == 0:\n",
        "    return True\n",
        "  firstClass = X[0][\"CLASS\"]\n",
        "  for elem in X:\n",
        "    if elem[\"CLASS\"] != firstClass:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def id3(X, A):\n",
        "    # TODO Cerință 2\n",
        "    if isLeaf(X, A) == True:\n",
        "      return Node(majClass(X))\n",
        "    bestAttr = A[0]\n",
        "    bestGain = -1\n",
        "\n",
        "    for elem in A:\n",
        "      newGain = gain(X, elem)\n",
        "      if bestGain < newGain:\n",
        "        bestGain = newGain\n",
        "        bestAttr = elem\n",
        "\n",
        "    auxA = A[:]\n",
        "    auxA.remove(bestAttr)\n",
        "    uniqueVals = []\n",
        "    auxX = X\n",
        "    tree = Node(bestAttr)\n",
        "    for elem in X:\n",
        "      if not elem[bestAttr] in uniqueVals:\n",
        "        tree.children[elem[bestAttr]] = id3(filterX(X, bestAttr, elem[bestAttr]), auxA)\n",
        "        uniqueVals.append(elem[bestAttr])  \n",
        "    \n",
        "    return tree\n",
        "\n",
        "treeId3 = id3(auxEx, auxAtt)\n",
        "treeId3.display(\"\")\n",
        "\n",
        "def evaluate(tree, example):\n",
        "    # TODO Cerință 2\n",
        "    # Functia intoarce clasa prezisa de arborele `tree` pentru exemplul `example`\n",
        "    if type(tree) == list:\n",
        "      return evaluateForest(tree, example)\n",
        "    else:\n",
        "      return evaluateTree(tree, example)\n",
        "\n",
        "def evaluateTree(tree, example):\n",
        "  if not bool(tree.children) == True:\n",
        "    return tree.label\n",
        "  currLabel = tree.label\n",
        "  currBranch = example[currLabel]\n",
        "  if currBranch in tree.children:\n",
        "    return evaluate(tree.children[currBranch], example)\n",
        "  return 'NoData'\n",
        "\n",
        "print(\"\\nPredictia pentru prima valoare este \" + evaluate(root2, auxEx[0]))\n",
        "\n",
        "def precision(tree, X, c):\n",
        "    prec = 0\n",
        "    predicted_ct = 0\n",
        "    \n",
        "    for ex in X:\n",
        "        pred_c = evaluate(tree, ex)\n",
        "        if pred_c == c:\n",
        "            predicted_ct += 1\n",
        "            if ex['CLASS'] ==c:\n",
        "                prec += 1\n",
        "    \n",
        "    if predicted_ct != 0:\n",
        "        return prec / predicted_ct\n",
        "    return 0\n",
        "    \n",
        "\n",
        "def recall(tree, X, c):\n",
        "    X_c = list(filter(lambda ex: ex['CLASS'] == c, X))\n",
        "    recall = 0\n",
        "    \n",
        "    for ex in X_c:\n",
        "        pred_c = evaluate(tree, ex)\n",
        "        if pred_c == c:\n",
        "            recall += 1\n",
        "            \n",
        "    recall /= len(X_c)\n",
        "    return recall\n",
        "    \n",
        "def accuracy(tree, X):\n",
        "  count = 0\n",
        "  for x in X:\n",
        "    if evaluate(tree, x) == x['CLASS']:\n",
        "      count += 1\n",
        "  return 1.0 * count / len(X)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Outlook\n",
            "\tsunny\n",
            "\t\tHumidity\n",
            "\t\t\thigh\n",
            "\t\t\t\tno\n",
            "\t\t\tnormal\n",
            "\t\t\t\tyes\n",
            "\tovercast\n",
            "\t\tyes\n",
            "\train\n",
            "\t\tWindy\n",
            "\t\t\tfalse\n",
            "\t\t\t\tyes\n",
            "\t\t\ttrue\n",
            "\t\t\t\tno\n",
            "\n",
            "Predictia pentru prima valoare este no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFh6b_z0vxhk"
      },
      "source": [
        "3. [4 pct] Implementați clasificator de tip pădure de arbori aleatori construind *n* arbori de adâncime maximă *d* fiecare dintre aceștia pornind de la o submulțime aleatoare a lui X.\n",
        "\n",
        "    Folosiți funcția *randomTree* de la cerința 1.\n",
        "  * Porniți de la *n = 100*, *d = 3* și submulțimi formate din 50% din elementele lui X alese la întamplare și experimentați cu acești hiperparametrii.\n",
        "  * Pentru predicția clasei pentru obiecte noi alegeți clasa majoritară\n",
        "  * Comparați rezultatele obținute folosind un singur arbore construit cu ID3 și o pădure de arbori aleatori. Discuție după *zgomot*, *overfitting*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LOaeUgIez66"
      },
      "source": [
        "def randomForest(X, n, d):\n",
        "    # TODO Cerință 3\n",
        "    trees = []\n",
        "    for i in range(n):\n",
        "      Attr = attributes[:]\n",
        "      newSize = len(X) * P / 100\n",
        "      newX = random.sample(X, int(newSize))\n",
        "      trees.append(randomTree(d, newX, Attr))\n",
        "    return trees\n",
        "    \n",
        "def evaluateForest(trees, example):\n",
        "  results = []\n",
        "  for tree in trees:\n",
        "    foundClass = evaluate(tree, example)\n",
        "    if foundClass != \"NoData\":\n",
        "      results.append(foundClass)\n",
        "  bestClass = ''\n",
        "  bestCount = 0\n",
        "  uniques = {}\n",
        "  for elem in results:\n",
        "    if elem not in uniques: \n",
        "      uniques[elem] = results.count(elem)\n",
        "      if uniques[elem] > bestCount:\n",
        "        bestCount = uniques[elem]\n",
        "        bestClass = elem\n",
        "  return bestClass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykSNuUALFiHX",
        "outputId": "da5d6ac2-ed0b-4383-d459-21dcae48b0ea"
      },
      "source": [
        "# testare\n",
        "# treeId3 este arborele generat folosind id3\n",
        "randForest = randomForest(auxEx, 10, 3)\n",
        "print(\"Id3 ------- Random Forest\")\n",
        "print(\"\\nAccuracy\")\n",
        "print(str(accuracy(treeId3, auxEx)) + \" ------- \" + str(accuracy(randForest, auxEx)))\n",
        "for clasa in classes:\n",
        "  print(\"\\nClasa \" + clasa)\n",
        "  print(\"Precision\")\n",
        "  print(str(precision(treeId3, auxEx, clasa)) + \" ------- \" + str(precision(randForest, auxEx, clasa)))\n",
        "  print(\"Recall\")\n",
        "  print(str(recall(treeId3, auxEx, clasa)) + \" ------- \" + str(recall(randForest, auxEx, clasa)))\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Id3 ------- Random Forest\n",
            "\n",
            "Accuracy\n",
            "1.0 ------- 0.9285714285714286\n",
            "\n",
            "Clasa no\n",
            "Precision\n",
            "1.0 ------- 0.8333333333333334\n",
            "Recall\n",
            "1.0 ------- 1.0\n",
            "\n",
            "Clasa yes\n",
            "Precision\n",
            "1.0 ------- 1.0\n",
            "Recall\n",
            "1.0 ------- 0.8888888888888888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzAB53E6HEJN"
      },
      "source": [
        "## 7. Set de date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93rR0yIOflFr"
      },
      "source": [
        "În cadrul acestui laborator se vor folosi seturile de date [Car Evaluation](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation), [Chess](https://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King-Pawn%29) și [Tennis](https://www.kaggle.com/fredericobreno/play-tennis).\n",
        "\n",
        "Aceste seturi de date sunt \"ușor\" modificate astfel încât pe prima linie să se afle atributele și labelul/clasa din care face parte fiecare exemplu.\n",
        "\n",
        "Atributele datasetului *Chess* nu sunt intuitive, iar dacă doriți să aflați mai multe informații despre acestea, puteți accesa link-ul de [aici](https://pdfs.semanticscholar.org/db58/88d3f373aff2c6bd7b2f956b81c6896874a9.pdf?_ga=2.193733611.798337455.1582711694-486327444.1582711694)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnH2b3D0kXTd"
      },
      "source": [
        "## 8. Extra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5JsikeLkZJc"
      },
      "source": [
        "### 8.1 ID3 exemplu\n",
        "Un exemplu mai detaliat pentru construcția arborelui de decizie ID3 se poate găsi [aici](https://github.com/cs-pub-ro/ML/blob/master/lab/lab2/id3_example.pdf).\n",
        "\n",
        "### 8.2 CART\n",
        "Un alt algoritm utilizat poartă denumirea de CART (eng. Classification and Regression Tree). Dacă **ID3** utilizeaza **câștigul informațional (eng. information gain)**, **CART** utilizeaza o altă metrică numită **index-ul Gini (eng. Gini index sau Gini impurity)**.\n",
        "\n",
        "Pentru implementare, se urmăresc exact aceeași [pași ca la ID3](#scrollTo=rjYqUPSbe1gG), singura diferentă fiind modul în care se calculează atributul utilizat într-un *nod intermediar*.\n",
        "$$\n",
        "Gini(X, a) = 1 - \\sum_{c \\in C}{p(c | attr(X) = a) ^2}\n",
        "\\\\\n",
        "a^* = \\underset{a \\in A}{\\operatorname{arg min}}\\ Gini(X, a)\n",
        "$$"
      ]
    }
  ]
}